{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traffic Sign Recognition System\n",
        "\n",
        "A deep learning project for classifying traffic signs using Convolutional Neural Networks (CNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Setting up all necessary libraries for data processing, model building and visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Explore Dataset\n",
        "\n",
        "Loading the GTSRB dataset and exploring its structure and distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = 'gtsrb german trafficsign'\n",
        "train_path = os.path.join(data_dir, 'Train')\n",
        "test_path = os.path.join(data_dir, 'Test')\n",
        "\n",
        "def load_data():\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    for class_num in range(43):\n",
        "        class_path = os.path.join(train_path, str(class_num))\n",
        "        if os.path.exists(class_path):\n",
        "            for img_name in os.listdir(class_path):\n",
        "                try:\n",
        "                    img_path = os.path.join(class_path, img_name)\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.resize(img, (32, 32))\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    images.append(img)\n",
        "                    labels.append(class_num)\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "    \n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X, y = load_data()\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "print(f\"Number of samples: {len(X)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Synthetic Dataset\n",
        "\n",
        "Creating a synthetic dataset for testing when GTSRB is not available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(X) == 0:\n",
        "    print(\"Creating synthetic dataset for demonstration...\")\n",
        "    np.random.seed(42)\n",
        "    X = np.random.randint(0, 256, (5000, 32, 32, 3), dtype=np.uint8)\n",
        "    y = np.random.randint(0, 43, 5000)\n",
        "    print(f\"Synthetic dataset created: {X.shape}\")\n",
        "\n",
        "class_names = {\n",
        "    0: 'Speed limit (20km/h)', 1: 'Speed limit (30km/h)', 2: 'Speed limit (50km/h)',\n",
        "    3: 'Speed limit (60km/h)', 4: 'Speed limit (70km/h)', 5: 'Speed limit (80km/h)',\n",
        "    6: 'End of speed limit (80km/h)', 7: 'Speed limit (100km/h)', 8: 'Speed limit (120km/h)',\n",
        "    9: 'No passing', 10: 'No passing veh over 3.5 tons', 11: 'Right-of-way at intersection',\n",
        "    12: 'Priority road', 13: 'Yield', 14: 'Stop', 15: 'No vehicles',\n",
        "    16: 'Veh > 3.5 tons prohibited', 17: 'No entry', 18: 'General caution',\n",
        "    19: 'Dangerous curve left', 20: 'Dangerous curve right', 21: 'Double curve',\n",
        "    22: 'Bumpy road', 23: 'Slippery road', 24: 'Road narrows on the right',\n",
        "    25: 'Road work', 26: 'Traffic signals', 27: 'Pedestrians', 28: 'Children crossing',\n",
        "    29: 'Bicycles crossing', 30: 'Beware of ice/snow', 31: 'Wild animals crossing',\n",
        "    32: 'End speed + passing limits', 33: 'Turn right ahead', 34: 'Turn left ahead',\n",
        "    35: 'Ahead only', 36: 'Go straight or right', 37: 'Go straight or left',\n",
        "    38: 'Keep right', 39: 'Keep left', 40: 'Roundabout mandatory',\n",
        "    41: 'End of no passing', 42: 'End no passing veh > 3.5 tons'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualization\n",
        "\n",
        "Visualizing sample images and class distribution in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(X[i])\n",
        "    plt.title(f'Class: {y[i]} - {class_names.get(y[i], \"Unknown\")}', fontsize=8)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "plt.bar(unique, counts)\n",
        "plt.xlabel('Traffic Sign Classes')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Distribution of Traffic Sign Classes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Normalizing pixel values and preparing data for model training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X.astype('float32') / 255.0\n",
        "y_categorical = to_categorical(y, num_classes=43)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of classes: {y_categorical.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build CNN Model Architecture\n",
        "\n",
        "Creating a deep convolutional neural network for traffic sign classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_cnn_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        \n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        \n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.25),\n",
        "        \n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(43, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_cnn_model()\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Training Callbacks\n",
        "\n",
        "Configuring callbacks for learning rate reduction and early stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', \n",
        "    factor=0.2, \n",
        "    patience=3, \n",
        "    min_lr=0.0001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [reduce_lr, early_stopping]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model\n",
        "\n",
        "Training the CNN model on the traffic sign dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.save('traffic_sign_model.h5')\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training History Visualization\n",
        "\n",
        "Plotting training and validation loss and accuracy curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Evaluating the trained model on test data and generating performance metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=[class_names[i] for i in range(43)]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "Creating and visualizing the confusion matrix for detailed performance analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=[f\"{i}\" for i in range(43)],\n",
        "            yticklabels=[f\"{i}\" for i in range(43)])\n",
        "plt.title('Confusion Matrix - Traffic Sign Classification')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.show()\n",
        "\n",
        "accuracy_per_class = cm.diagonal() / cm.sum(axis=1)\n",
        "print(\"\\nAccuracy per class:\")\n",
        "for i, acc in enumerate(accuracy_per_class):\n",
        "    print(f\"Class {i} ({class_names[i]}): {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Predictions Visualization\n",
        "\n",
        "Visualizing model predictions on sample test images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(X_test[i])\n",
        "    true_class = y_true_classes[i]\n",
        "    pred_class = y_pred_classes[i]\n",
        "    confidence = np.max(y_pred[i]) * 100\n",
        "    \n",
        "    color = 'green' if true_class == pred_class else 'red'\n",
        "    plt.title(f'True: {true_class} ({class_names[true_class][:15]})\\n'\n",
        "              f'Pred: {pred_class} ({class_names[pred_class][:15]})\\n'\n",
        "              f'Conf: {confidence:.1f}%', \n",
        "              color=color, fontsize=8)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model and Class Names\n",
        "\n",
        "Saving the trained model and class names for future use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('class_names.pickle', 'wb') as f:\n",
        "    pickle.dump(class_names, f)\n",
        "\n",
        "print(\"Model and class names saved successfully!\")\n",
        "print(\"Files created:\")\n",
        "print(\"- traffic_sign_model.h5\")\n",
        "print(\"- class_names.pickle\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
